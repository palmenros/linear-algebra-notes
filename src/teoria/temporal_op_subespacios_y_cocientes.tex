% !TeX root = ../algebra_lineal.tex

\documentclass[../algebra_lineal.tex]{subfiles}

\begin{document}

\section{Operaciones con subespacios vectoriales}

Una vez definidos los subespacios vectoriales, nos interesa poder operar con ellos. Los subespacios vectoriales no dejan de ser subconjuntos del espacio vectorial, por lo que tiene sentido analizar el comportamiento de las operaciones propias de conjuntos, como son la intersección y la unión. Introducimos algunas definiciones para formalizar esto.

\begin{definition}
    Si $V$ es un conjunto, definimos las partes de $V$ como
    \[
        \partesde{V} = \set{A : A \subseteq V} 
    \] 
    es decir, como el conjunto de todos los subconjuntos de $V$. 
\end{definition}

Existen dos operaciones muy conocidas sobre conjuntos que son la unión y la intersección.

\begin{definition}[Intersección]
    Sea $I$ un conjunto de índices (posiblemente no numerable) tal que $\forall i \in I, \spc A_i \in \partesde{V}$, entonces se define la intersección de los conjuntos $A_i$ como
    \[ \bigcap_{i \in I}A_i = \set{\vx \in V : \vx \in A_i \spc \forall i \in I} \]
    es decir, el conjunto de los elementos comunes a todos los $A_i$.
\end{definition}

\begin{definition}[Unión]
    Sea $I$ un conjunto de índices (posiblemente no numerable) tal que $\forall i \in I, \spc A_i \in \partesde{V}$, entonces se define la unión de los conjuntos $A_i$ como
    \[\bigcup_{i \in I}A_i = \set{\vx \in V : \exists i \in I \st \vx \in A_i}\]
    es decir, el conjunto que contiene a todos los elementos comunes y no comunes de los $A_i$.
\end{definition}

Sería muy conveniente que la intersección o unión de subespacios vectoriales fuese a su vez otro subespacio vectorial. Veremos más adelante si esto es cierto, pero antes introduciremos algo de notación útil.

\begin{definition}
    Sea $V$ un \kvspace, definimos el conjunto de todos los espacios vectoriales de $V$ como
    \[
        \subespaciosde{V} = \set{L \in \partesde{V} : L \mathrm{\, \, es \, \, subespacio \, \, vectorial }}
    \]
\end{definition}

Vamos ahora a demostrar que la intersección de subespacios vectoriales es de nuevo un subespacio vectorial.

\begin{proposition}
    Sea $I$ un conjunto y $\forall i \in I$ sea $L_i \in \subespaciosde{V}$, entonces $\displaystyle\bigcap_{i \in I}{L_i} \in \subespaciosde{V}$
\end{proposition}

\begin{proof}
    Demostraremos que es parte estable, comenzando con la suma.
    Sean $\vx, \vy \in \displaystyle\bigcap_{i \in I}L_i \Rightarrow \vx, \vy \in L_i, \spc \forall i \in I \Rightarrow \vx + \vy \in L_i \spc \forall i \in I$, por lo que $\vx + \vy \in \displaystyle\bigcap_{i \in I}L_i$.

    Veamos ahora la multiplicación por escalar. Sea $\vx \in \displaystyle\bigcap_{i \in I}L_i$ y sea $a \in \K$. Entonces, $\vx \in L_i, \spc \forall i \in I \Rightarrow a \cdot \vx \in L_i \spc \forall i \in I$, por lo que $a \cdot \vx \in \displaystyle\bigcap_{i \in I}L_i$.
\end{proof}

Sin embargo, no tenemos tanta suerte con la unión. Veremos con un ejemplo que la unión de subespacios vectoriales no es un subespacio vectorial. Intuitivamente, dos rectas que se cortan no forman un subespacio vectorial (sería necesario el plano entero que las une).

\begin{example}
    Sean $\set{\vv_1, \vv_2} \subseteq V$ linealmente independientes y sean
    \begin{align*}
        L_1 = \lspan{\set{\vv_1}} &= \set{a \cdot \vv_1 : a \in \K } \in \subespaciosde{V} \\
        L_2 = \lspan{\set{\vv_2}} &= \set{a \cdot \vv_2 : a \in \K } \in \subespaciosde{V}
    \end{align*}
    En el caso de que $L_1 \cup L_2 \in \subespaciosde{V}$, entonces como $\vv_1 \in L_1 \subseteq L_1 \cup L_2$ y $\vv_2 \in L_2 \subseteq L_1 \cup L_2$, tendríamos que $\vv_1 + \vv_2 \in L_1 \cup L_2$. Sin pérdida de generalidad (podemos intercambiar si no $\vv_1$ y $\vv_2$), suponemos que $\vv_1 + \vv_2 \in L_1$, por lo que $\exists a \in \K \st \vv_1 + \vv_2 = a \cdot \vv_1 \Rightarrow \exists a \in \K \st \parens{1-a}\vv_1 + \vv_2 = \zv$. Hemos llegado a una contradicción, ya que $\set{\vv_1, \vv_2}$ son linealmente independientes y el coeficiente de $\vv_2$ es $1 \ne 0$. Por tanto, $L_1 \cup L_2 \notin \subespaciosde{V}$. 
\end{example}

A pesar de que la unión no sea un subespacio vectorial, nos interesaría poder tener un concepto parecido. Podemos definir entonces el subespacio vectorial más pequeño que contiene a la unión (en el ejemplo de las dos rectas que se cortan, sería el plano que las contiene). 

\begin{definition}[Suma]
    Sean $L_1, L_2 \in \subespaciosde{V}$, llamaremos suma de $L_1$ y $L_2$ al subespacio vectorial 
    \[
        L_1 + L_2 = \lspan{L_1 \cup L_2} = \bigcap_{L_1 \cup L_2 \subseteq L \in \subespaciosde{V}}L
    \]
\end{definition}

Un gran inconveniente de esta definición es que no ofrece un método directo para calcular $L_1 + L_2$. En la siguiente proposición encontramos una caracterización computable para $L_1 + L_2$.

\begin{proposition}
    Sea $L' = \set{\vx_1 + \vx_2 : \vx_1 \in L_1, \, \vx_2 \in L_2}$, entonces, $L_1 + L_2 = L'$.
\end{proposition}

\begin{proof}
    Para demostrar que $L'$ es el menor subespacio vectorial que contiene a $L_1 \cup L_2$ debemos demostrar que efectivamente es un subespacio vectorial, que contiene a $L_1 \cup L_2$ y que es el menor que lo hace.

    \begin{enumerate}
        \item Comencemos demostrando que $L'$ es un subespacio vectorial.

        Si $\vx, \vy \in L' \Rightarrow \exists \vx_1, \vy_1 \in L_1, \vx_2, \vy_2 \in L_2 \st \vx = \vx_1 + \vx_2$ y $\vy = \vy_1 + \vy_2$. Entonces,
        \[
            \vx + \vy = \parens{\vx_1 + \vx_2} + \parens{\vx_1 + \vx_2} =  \underbrace{{(\underbrace{\vx_1}_{\in L_1} + \underbrace{\vy_1}_{\in L_1}})}_{\in L_1} + \underbrace{{(\underbrace{\vx_2}_{\in L_2} + \underbrace{\vy_2}_{\in L_2}})}_{\in L_2} \in L'
        \]

        Si $\vx \in L'$ y $a \in \K \Rightarrow \exists \vx_1 \in L_1 \vx_2 \in L_2$ tal que $\vx=\vx_1+\vx_2$. Entonces,
        \[
            a \cdot \vx = a \cdot \parens{\vx_1 + \vx_2} = \underbrace{a \vx_1}_{\in L_1} +  \underbrace{a \vx_2}_{\in L_2} \in L'
        \]

        \item Veamos ahora que $L_1 \cup L_2 \subseteq L'$. Si $\vx_1 \in L_1 \Rightarrow \vx_1 = \underbrace{\vx_1}_{\in L_1} + \underbrace{\zv}_{\in L_2} \in L'$, por lo que $L_1 \subseteq L'$. Análogamente, $\vx_2 \in L_2 \Rightarrow \vx_2 = \underbrace{\zv}_{\in L_1} + \underbrace{\vx_2}_{\in L_2} \in L'$, por lo que $L_2 \subseteq L'$. Como $L_1 \subseteq L'$ y $L_2 \subseteq L'$, entonces $L_1 \cup L_2 \subseteq L'$.
        
        \item Por último demostraremos que si $L \in \subespaciosde{V} \st L_1 \cup L_2 \subseteq L \Rightarrow L' \subseteq L$. Efectivamente, si $\vx \in L' \Rightarrow \exists \vx_1 \in L_1, \vx_2 \in L_2$ tal que
        \[
            \vx = \underbrace{\vx_1}_{\in L_1 \subseteq L} + \underbrace{\vx_2}_{\in L_2 \subseteq L} \in L
        \]
        donde la pertenencia a $L$ se da por ser este un espacio vectorial.
    \end{enumerate}
\end{proof}

Una ventaja de esta caracterización es que nos permite demostrar proposiciones como la siguiente sin mayor esfuerzo.

\begin{proposition}
    La suma de subespacios vectoriales es asociativa, es decir, si $L_1, L_2, L_3 \in \subespaciosde{V}$, entonces  $\parens{L_1 + L_2} + L_3 = L_1 + \parens{L_2 + L_3}$
\end{proposition}
\begin{proof}
    \begin{align*}
        \parens{L_1 + L_2} + L_3 &= \set{\vx + \vx_3 : \vx \in L_1 + L_2, \vx_3 \in L_3}\\
            &= \set{\parens{\vx_1 + \vx_ 2} + \vx_3 : \vx_1 \in L_1, \vx_2 \in L_2, \vx_3 \in L_3}\\
            &= \set{\vx_1 + \parens{\vx_ 2 + \vx_3} : \vx_1 \in L_1, \vx_2 \in L_2, \vx_3 \in L_3}\\
            &= \set{\vx_1 + \vx : \vx_1 \in L_1, \vx \in L_2 + L_3} \\
            &= L_1 + \parens{L_2 + L_3}
    \end{align*}
\end{proof}

Intuitivamente, los conceptos de unión y suma de subespacios vectoriales son conceptos duales. El siguiente teorema es un resultado profundo que relaciona las dimensiones de ambas operaciones.

\begin{theorem} [Fórmula de Grassmann]
    Sean $L_1, L_2 \in \subespaciosde{V}$. Entonces,
    \[
        \dim{L_1 + L_2} = \dim{L_1} + \dim{L_2} - \dim{L_1 \cap L_2}
    \]
\end{theorem}

\begin{proof}
    En primer lugar observamos que $L_1 \cap L_2 \in \subespaciosde{L_1}$ y  $L_1 \cap L_2 \in \subespaciosde{L_2}$. Además, $L_1, L_2 \in \subespaciosde{L_1 + L_2}$. Sea $\set{\vlst{u}{r}}$ una base de $L_1 \cap L_2$, por lo que $r = \dim{L_1 \cap L_2}$. Podemos extender esta base a bases de $L_1$ y $L_2$ por ser subespacio vectorial. Sean $\set{\vlst{u}{r}, \vu_{r+1}, \dots, \vu_{r+p}}$ y $\set{\vlst{u}{r}, \vv_{r+1}, \dots, \vv_{r+q}}$ bases de $L_1$ y $L_2$ respectivamente. Por tanto, $r+p=\dim{L_1}$ y $r+q=\dim{L_2}$.
    Vamos a demostrar que  $\set{\vlst{u}{r}, \vu_{r+1}, \dots, \vu_{r+p}, \vv_{r+1}, \dots, \vv_{r+q}}$ es una base de $L_1+L_2$, por lo que $\dim{L_1+L_2} = r+p+q = (r+p) + (r+q) - r = \dim{L_1} + \dim{L_2} - \dim{L_1 \cap L_2} $ y habríamos completado la demostración.

    \begin{enumerate}
        \item Demostremos primero que es sistema de generadores. Primero, notamos que 
        \begin{align*}
            \vlst{u}{r}, \vu_{r+1}, \dots, \vu_{r+p} &\in L_1 \subseteq L_1 + L_2 \\
            \vv_{r+1}, \dots, \vv_{r+q} &\in L_2 \subseteq L_1 + L_2
        \end{align*}
        Por tanto, si $\vx \in L_1 + L_2 \Rightarrow \exists \vx_1 \in L_1, \, \vx_2 \in L_2$ tal que $\vx = \vx_1 + \vx_2$.
        \begin{align*}
          \vx_1 \in L_1 &\Rightarrow \exists \slst{a}{r}, a^{r+1}, \dots, a^{r+p} \in \K \st \\
                        &\vx_1 = \lincomb{a}{u}{r} + a^{r+1}\vu_{r+1} + \dots + a^{r+p}\vu_{r+p} \\
            \vx_2 \in L_2 &\Rightarrow \exists \slst{b}{r}, b^{r+1}, \dots, b^{r+q} \in \K \st \\
                &\vx_2 = \lincomb{b}{u}{r} + b^{r+1}\vv_{r+1} + \dots + b^{r+q}\vv_{r+q}
        \end{align*}
        Sumando ambas tenemos que 
        \begin{align*}
            \vx = \, &\vx_1 + \vx_2 = (a^1 + b^1)\vu_1 + (a^2 + b^2)\vu_2 + \dots + (a^r + b^r)\vu_r + a^{r+1}\vu_{r+1} + \dots + \\
                  &+ a^{r+p} \vu_{r+p} + b^{r+1}\vv_{r+1} + \dots + b^{r+q}\vv_{r+q}
        \end{align*}
        Por tanto, es sistema de generadores.
        \item Veamos ahora que los vectores son linealmente independientes. \\
        Sean $\slst{a}{r+1}, \dots, a^{r+p}, b^{r+1}, \dots, b^{r+q} \in \K$ tal que 
        \[
            \underbrace{a^1\vu_{1} + a^2\vu_{2} + \dots + a^r\vu_{r} + \dots + a^{r+p}\vu_{r+p}}_{\vy \in L_1} + \underbrace{b^{r+1}\vv_{r+1} +\dots + b^{r+q}\vv_{r+q}}_{-\vy \in L_2} = \zv
        \]
        Hemos visto que $-\vy \in L_2$, pero además, $-\vy = (-1) \cdot \vy \in L_1$, por lo que $-\vy \in L_1 \cap L_2$. Por pertenecer a $L_1$, $\exists \slst{b}{r} \in \K$ tal que $-\vy = \lincomb{b}{u}{r}$ y por la definición que hemos dado de $-\vy$, $-\vy = b^{r+1} \vv_{r+1} + \dots + b^{r+q}\vv_{r+q}$. Restando la primera igualdad a la segunda llegamos a que   
        \[
            \zv = \parens{-b^1} \vu_1 + \parens{-b^2} \vu_2 + \dots + \parens{-b^r}\vu_{r} + b^{r+1}\vv_{r+1} + \dots + b^{r+q} \vv_{r+q}
        \]
        Como $\set{\vlst{u}{r}, \vv_{r+1}, \dots, \vv_{r+q}}$ es base de $L_2$, entonces son linealmente independientes, por lo que todos los coeficientes de la combinación lineal son 0. Es decir,
        \[
            \parens{-b^1} = \parens{-b^2} = \dots = \parens{-b^r} = b^{r+1} = \dots = b^{r+q} = 0
        \]
        Como $b^{r+1} = \dots = b^{r+q} = 0$, entonces $-\vy = 0 \Rightarrow \vy = 0$. Entonces,
        \[
            \vy = \zv = \lincomb{a}{u}{r} + a^{r+1}\vu_ {r+1} + \dots + a^{r+p}\vu_{r+p} 
        \]
        De nuevo, por ser $\set{\vlst{u}{r}, \vu_{r+1}, \dots, \vu_{r+p}}$ base de $L_1$, los vectores son linealmente independientes, por lo que los coeficientes de la combinación lineal son 0. Por la caracterizacion de independencia lineal, hemos demostrado que el sistema de generadores original es también linealmente independiente, por lo que es base.
    \end{enumerate}
\end{proof}

Un caso qu simplifica la fórmula de Grassman es $\dim{L_1 \cap L_2} = 0$, es decir, $L_1 \cap L_2 = \zvs$. Este caso, además de simplificar la fórmula, tiene propiedades muy interesantes, por lo que se merece una definición.

\begin{definition}[Suma directa]
    Sean $L_1, L_2 \in \subespaciosde{V}$, diremos que la suma $L_1 + L_2$ es directa y la escribiremos como $L_1 \oplus L_2$ si $L_1 \cap L_2 = \zvs$. Por tanto, $\dim{L_1 \oplus L_2} = \dim{L_1} + \dim{L_2}$   
\end{definition}

Una propiedad importante de la suma directa es que nos permite descomponer cada vector de $L_1 \oplus L_2$ en dos componentes únicas de $L_1$ y $L_2$, lo que nos será muy útil en el futuro.

\begin{proposition}
    Sean $L_1, L_2 \in \subespaciosde{V}$. Entonces $L_1 \oplus L_2$ es directa si y solamente si $\forall x \in L_1 + L_2, \spc \exists! \vx_1 \in L_1, \, \vx_2 \in L_2  \st \vx = \vx_1 + \vx_2$.
\end{proposition}

\begin{proof}
    Estudiemos las implicaciones por separado.
    \begin{enumerate}
        \item[\protect\fbox{$\Rightarrow$}] Supongamos $L_1 \oplus L_2$ y sean $\vx_1, \vy_1 \in L_1$ y $\vx_2, \vy_2 \in L_2$ tal que $\vx_1 + \vx_2 = \vy_1 + \vy_2$, por lo que
        \[
            \underbrace{\underbrace{\vx_1}_{\in L_1} - \underbrace{\vy_1}_{\in L_1}}_{\in L_1} = \underbrace{\underbrace{\vy_2}_{\in L_2} - \underbrace{\vx_2}_{\in L_2}}_{\in L_2}
        \] 
        
        Por tanto, $\vx_1 - \vy_1 \in L_1 \cap L_2$. Pertenece a $L_2$ porque es igual al término de la derecha de la igualdad que a su vez pertenece a $L_2$. Como $\ds{L_1}{L_2} \implies \zvsint{L_1}{L_2}$ y $\vx_1 - \vy_1 \in L_1 \cap L_2 = \zvs \implies \vx_1 - \vy_1 = 0 \implies \vx_1 = \vy_1$. Hacemos el mismo proceso para $\vy_2 - \vx_2$ y llegamos a que $\vx_2 = \vy_2$ también, por lo que la descomposición es única.

        \item[\protect\fbox{$\Leftarrow$}] Sea $\vy \in L_1 \cap L_2$, podemos expresar $\vy = \underbrace{\vy}_{L_1} + \underbrace{\zv}_{L_2} = \underbrace{\zv}_{L_1} + \underbrace{\vy}_{L_2}$. Como la descomposición es única, $\vy = \zv$. Por tanto, $\zvsint{L_1}{L_2}$, por lo que $\ds{L_1}{L_2}$.  
    \end{enumerate}
\end{proof}

Aprovecharemos esta caracterización para definir la suma directa de más de dos subespacios. 
\begin{definition}
    Sea $r \in \N$ y sean $\dlst{L}{r} \in \subespaciosde{V}$. Diremos que la suma de $\dlst{L}{r}$ es directa si $\forall \vx \in L_1 + L_2 + \dots + L_r, \spc \forall i \in \set{1, \dots, r}, \spc \exists ! \, \vx_i \in L_i$ tal que $\vx = \vx_1 + \vx_2 + \dots + \vx_r$ y escribiremos $L_1 \oplus L_2 \oplus \dots \oplus L_r$.
\end{definition}

Planteamos una caracterización similar a la ya dada para la suma directa de dos elementos.
\begin{proposition}
    Sean $\dlst{L}{r} \in \subespaciosde{V}$. Entonces $L_1 \oplus L_2 \oplus \dots L_r$ si y solo si $\forall i \in \set{1, \dots, r}, \zvsint{L_i}{\parens{\pidlst{L}{r}{i}{+}}}$.
\end{proposition}
\begin{proof}
    Demostramos por separado ambas implicaciones.
    \begin{enumerate}
        \item[\protect\fbox{$\Rightarrow$}] Sea $ i \in \set{1, \dots, r}$, si $\vx_i \in L_i \cap \parens{\pidlst{L}{r}{i}{+}}$, entonces, como $\vx_i \in \parens{\pidlst{L}{r}{i}{+}} \spc  \forall j \in \set{1, \dots, i-1, i+1, \dots, r}, \spc \exists \vx_j \in L_j$ tal que
        \begin{align*}
            \vx_i &= \underbrace{\zv}_{\in L_1} + \dots + \underbrace{\zv}_{\in L_{i-1}} + \underbrace{\vx_i}_{\in L_i} + \underbrace{\zv}_{\in L_{i+1}} + \dots + \underbrace{\zv}_{L_{r}} \\
                 &=  \underbrace{\vx_1}_{\in L_1} + \dots + \underbrace{\vx_{i-1}}_{\in L_{i-1}} + \underbrace{\zv}_{\in L_i} + \underbrace{\vx_{i+1}}_{\in L_{i+1}} + \dots + \underbrace{\vx_{r}}_{L_{r}}
        \end{align*}
        
        Como la descomposición es única, tenemos entonces que $\vx_i = \zv$.
        
        \item[\protect\fbox{$\Leftarrow$}] Sea $\vx \in \pdlst{L}{r}{+}$ y supongamos que $\forall j \in \set{1, \dots, r}, \spc \exists \vx_j, \vy_j$ tal que
        \begin{align*}
            \vx &= \pcvlst{x}{r}{i}{+} \\
                &= \pcvlst{y}{r}{i}{+}
        \end{align*}
        Entonces, despejando, $\forall i \in \set{1, \dots, r}$ se tiene que 
        \[
            \underbrace{\underbrace{\vx_i}_{\in L_i} - \underbrace{\vy_i}_{\in L_i}}_{\in L_i} = \underbrace{\parens{\vy_1 - \vx_1}}_{\in L_1} + \dots + \underbrace{\parens{\vy_{i-1} - \vx_{i-1}}}_{\in L_{i-1}} + \underbrace{\parens{\vy_{i+1} - \vx_{i+1}}}_{\in L_{i+1}} + \dots + \underbrace{\parens{\vy_{r} - \vx_{r}}}_{\in L_r} 
        \]
        Por tanto, $\vx_i - \vy_i \in L_i \cap \parens{\pidlst{L}{r}{i}{+}} = \zvs \Rightarrow \vx_i - \vy_i = \zv$. Por tanto, $\vx_i = \vy_i \spc \forall i \in \set{1, \dots, r}$, la descomposición es única y $\pdlst{L}{r}{\oplus}$
    \end{enumerate}
\end{proof}

Una ventaja de las sumas directas es que podemos crear bases para la suma directa concatenando las bases de los sumandos.

\begin{proposition}
    Si $\pdlst{L}{r}{\oplus}$ y $\forall i \in \set{1, \dots, r}, \set{\vlstp{u}{n_i}{i}}$ es base de $L_i$, entonces $\set{\vlstp{u}{n_1}{1}, \dots, \vlstp{u}{n_i}{i}, \dots, \vlstp{u}{n_r}{r}}$ es base de $\pdlst{L}{r}{\oplus}$.
\end{proposition}

\begin{proof}
    Veremos por separado que es linealmente independiente y sistema de generadores.
    \begin{enumerate}
        \item Veamos que es sistema de generadores. Si $\vx \in \pcvlst{L}{r}{i}{\oplus}$, entonces $\exists ! \vx_1 \in L_1, \dots, \vx_i \in L_i, \dots, \vx_r \in L_r $ tal que
        \[
            \vx = \underbrace{\vx_1}_{\in L_1} + \dots + \underbrace{\vx_i}_{\in L_i} + \dots +  \underbrace{\vx_r}_{\in L_r}
        \]
        Existen $\slstp{a}{n_1}{1}, \dots, \slstp{a}{n_i}{i}, \dots \slstp{a}{n_r}{r} \in \K$ tales que $\forall i \in \set {1, \dots, r}$
        \[
            \vx_i = \lincombp{a}{u}{n_i}{i}
        \]
        Juntando todos,
        \begin{align*}
            \vx &= \lincombp{a}{u}{n_1}{1} + \dots + \lincombp{a}{u}{n_i}{i} + \\
             & \spc + \dots + \lincombp{a}{u}{n_r}{r}
        \end{align*}
        \item Veamos que son l.i. Sean $\slstp{b}{n_1}{1}, \dots, \slstp{b}{n_i}{i}, \dots \slstp{b}{n_r}{r} \in \K$ tal que
        \begin{align*}
            \zv &= \lincombp{b}{u}{n_1}{1} + \dots + \underbrace{\lincombp{b}{u}{n_i}{i}}_{\vy \in L_i \cap \parens{\pidlst{L}{r}{i}{+}} = \zvs } + \\
            & \spc + \dots + \lincombp{b}{u}{n_r}{r}
        \end{align*}
        Por tanto, como $\vy \in \zvs \Rightarrow \vy = \zv$, por lo que
        \[
            \vy = \zv = \lincombp{b}{u}{n_i}{i} 
        \]
        Como $\set{\vlstp{u}{n_i}{i}}$ es base, entonces $b_i^i=b_i^2= \dots = b_i^{n_i} = 0$. Como esto es cierto para todo $i \in \set{1, \dots, r}$, entonces los vectores son linealmente independientes. 
    \end{enumerate}
\end{proof}

\begin{corollary}
    $\dim{\pdlst{L}{r}{\oplus}} = \dim{L_1} + \dim{L_2} + \dots + \dim{L_r}$.
\end{corollary}

Introducimos ahora la noción de que dos subespacios vectoriales sean complementarios.

\begin{definition}
    Dos subespacios vectoriales $L_1, L_2 \in \subespaciosde{V}$ son complementarios o suplementarios si $L_1 \oplus L_2 = V$, es decir, si $\zvsint{L_1}{L_2}$ y $L_1 + L_2 = V$.
\end{definition}

Para finalizar esta sección, demostraremos que cualquier subespacio vectorial tiene un complementario.

\begin{proposition}
    Sea $L \in \subespaciosde{V}$, entonces $\exists L' \in \subespaciosde{V}$ tal que $L$ y $L'$ son complementarios.
\end{proposition}

\begin{proof}
    Sea $\set{\vlst{u}{r}}$ una base de L que ampliamos hasta una base $\set{\vlst{u}{r}, \vu_{r+1}, \dots, \vu_n}$ de $V$. Definimos $L'= \set{\vu_{r+1}, \dots, \vu_n}$. Veamos por separado que $L+L'=V$ y que $L_1 \cap L_2 = \zvs$.

    \begin{enumerate}
        \item Demostremos que $L+L'=V$. Sea $\vx \in V \Rightarrow \exists \cslst{a}{n}{r} \in \K$ tal que
        \[
            \vx = \underbrace{ \lincomb{a}{u}{r} }_{\in L} + \underbrace{a^{r+1}\vu_{r+1} + \dots + a^{n}\vu_{n} }_{\in L'}
        \]
        Por tanto $\vx \in L + L'$
        \item Veamos que $L \cap L' = \zvs$. Sea $\vx \in L \cap L' \Rightarrow \exists \cslst{a}{n}{r} \in \K$ tal que
        \begin{align*}
            \vx &= \lincomb{a}{u}{r}  & (\mathrm{por \spc pertenecer \spc a \spc} L) \\ 
            \vx &= a^{r+1}\vu_{r+1} + a^{r+2}\vu_{r+2} + \dots + a^n \vu_{n} &(\mathrm{por \spc pertenecer \spc a \spc} L') &
        \end{align*}
        Restando obtenemos
        \[
            \zv = \vx - \vx = \lincomb{a}{u}{r} + \parens{-a^{r+1}}\vu_{r+1} + \dots + \parens{-a^n}\vu_n 
        \]
        Como $\set{\vlst{u}{n}}$ es una base de $V$, esos vectores son linealmente independientes, por lo que $a^1=a^2=\dots=a^r=a^{r+1}=\dots=a^n=0$. Por tanto, $\vx = \zv$.
    \end{enumerate}
\end{proof}

\end{document}